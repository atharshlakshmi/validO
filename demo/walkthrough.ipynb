{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6e94250",
   "metadata": {},
   "source": [
    "### Walkthrough\n",
    "\n",
    "To show the inner working of the code, we use a small subset of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26c4e83",
   "metadata": {},
   "source": [
    "### Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fde4f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import spacy\n",
    "import re\n",
    "from transformers import pipeline\n",
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf922db",
   "metadata": {},
   "source": [
    "### Load Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e263bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 1500 to 1549\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   user_name    50 non-null     object\n",
      " 1   review_text  50 non-null     object\n",
      " 2   rating       50 non-null     int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data_path = '../data/clean/cleaned_combined_reviews.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "df2 = df.iloc[1500:1550].copy()\n",
    "df2.shape\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f1043",
   "metadata": {},
   "source": [
    "### Label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29889d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(\n",
    "    provider=\"nscale\",\n",
    "    api_key=os.environ[\"HF_TOKEN\"],\n",
    ")\n",
    "\n",
    "FEW_SHOT_EXAMPLES = \"\"\"\n",
    "You are a system that classifies Google location reviews into one of four categories:\n",
    "- Ad: Promotional or advertisement content.\n",
    "- Rant: Angry or exaggerated complaints, often with excessive punctuation or all-caps.\n",
    "- Irrelevant: Not related to the location being reviewed.\n",
    "- Valid: A genuine and relevant review about the location.\n",
    "\n",
    "Examples:\n",
    "Review: \"Best pizza in town! Fresh ingredients and great service.\"\n",
    "Label: Valid\n",
    "\n",
    "Review: \"BUY ONE GET ONE FREE! Come to my shop now, limited offer!\"\n",
    "Label: Ad\n",
    "\n",
    "Review: \"THIS PLACE IS THE WORST!!! NEVER COMING BACK. HORRIBLE SERVICE!!!!!\"\n",
    "Label: Rant\n",
    "\n",
    "Review: \"I think the government is doing a terrible job with taxes.\"\n",
    "Label: Irrelevant\n",
    "\"\"\"\n",
    "\n",
    "def create_batch_prompt(reviews):\n",
    "    reviews_list = \"\\n\".join(\n",
    "        [f\"Review {i+1}: {r}\" for i, r in enumerate(reviews)]\n",
    "    )\n",
    "    return f\"\"\"{FEW_SHOT_EXAMPLES}\n",
    "    Now classify the following reviews:\n",
    "    {reviews_list}\n",
    "\n",
    "    Output format:\n",
    "    Review 1: <Label>\n",
    "    Review 2: <Label>\n",
    "    ...\n",
    "    \"\"\"\n",
    "\n",
    "def classify_batch(reviews):\n",
    "    prompt = create_batch_prompt(reviews)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"Qwen/Qwen3-4B-Instruct-2507\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def label_reviews(df, text_col=\"review_text\", batch_size=100, max_reviews=1000):\n",
    "    labeled = []\n",
    "    reviews = df[text_col].astype(str).tolist()[:max_reviews]\n",
    "    \n",
    "    for i in range(0, len(reviews), batch_size):\n",
    "        batch = reviews[i:i+batch_size]\n",
    "        output = classify_batch(batch)\n",
    "\n",
    "        # Parse output: expects \"Review 1: Valid\" style\n",
    "        for line in output.splitlines():\n",
    "            if line.strip() and line.startswith(\"Review\"):\n",
    "                try:\n",
    "                    idx, label = line.split(\":\", 1)\n",
    "                    labeled.append(label.strip())\n",
    "                except:\n",
    "                    labeled.append(\"Unknown\")\n",
    "        \n",
    "        print(f\"Processed {i+len(batch)} / {len(reviews)}\")\n",
    "    \n",
    "    df = df.iloc[:max_reviews].copy()\n",
    "    df[\"label\"] = labeled\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "100d3b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50 / 50\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 1500 to 1549\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   user_name    50 non-null     object\n",
      " 1   review_text  50 non-null     object\n",
      " 2   rating       50 non-null     int64 \n",
      " 3   label        50 non-null     object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.7+ KB\n",
      "None\n",
      "              user_name                                        review_text  \\\n",
      "1500            Craig H  I’ve had my Sanctuary 2 sauna and red light fo...   \n",
      "1501   Dr Harold Patino  What can I say! Julie was fantastic and the pr...   \n",
      "1502   Lauren Kilbourne  Thank you so much Julie for your support in pu...   \n",
      "1503  Natural Baby Mama  Julie has been amazing throughout the entire b...   \n",
      "1504     Holly McGreevy  Working with Julie was an absolute pleasure! J...   \n",
      "\n",
      "      rating  label  \n",
      "1500       5  Valid  \n",
      "1501       5  Valid  \n",
      "1502       5  Valid  \n",
      "1503       5  Valid  \n",
      "1504       5  Valid  \n"
     ]
    }
   ],
   "source": [
    "df2 = label_reviews(df2)\n",
    "print(df2.info())\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65241af",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feac5dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    return text\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def tokenize(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "def all_caps_ratio(text):\n",
    "    words = text.split()\n",
    "    caps_words = [word for word in words if word.isupper()]\n",
    "    return len(caps_words) / len(words) if len(words) > 0 else 0\n",
    "\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "def calculate_relevancy_score(text):\n",
    "    # Can adjust this score based on sentiment, length, and keyword presence\n",
    "    # For example, the higher the sentiment score and review length, the more relevant it is\n",
    "    sentiment_score = sentiment_analyzer(text)[0]['score']\n",
    "    review_length = len(text.split())\n",
    "    caps_ratio = all_caps_ratio(text)\n",
    "    \n",
    "    # Simple heuristic: higher sentiment, longer review, lower caps_ratio = more trustworthy\n",
    "    relevancy_score = (sentiment_score * 40) + (review_length * 0.5) - (caps_ratio * 20)\n",
    "    return min(max(int(relevancy_score), 0), 100)  # Ensure the score is between 0 and 100\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# -----------------------\n",
    "# Load local model + tokenizer\n",
    "# -----------------------\n",
    "\n",
    "model_path = \"../models/trained_model\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_path,\n",
    "    local_files_only=True,\n",
    "    trust_remote_code=False\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_path,\n",
    "    local_files_only=True,\n",
    "    trust_remote_code=False\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# Define labels (must match training)\n",
    "# -----------------------\n",
    "LABELS = [\n",
    "    'admiration','amusement','anger','annoyance','approval','caring',\n",
    "    'confusion','curiosity','desire','disappointment','disapproval','disgust',\n",
    "    'embarrassment','excitement','fear','gratitude','grief','joy','love',\n",
    "    'nervousness','optimism','pride','realization','relief','remorse',\n",
    "    'sadness','surprise','neutral'\n",
    "]\n",
    "\n",
    "# -----------------------\n",
    "# Dataset class for inference\n",
    "# -----------------------\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=128):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.dataframe.iloc[idx]['review_text'])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "        }\n",
    "\n",
    "# -----------------------\n",
    "# Inference function\n",
    "# -----------------------\n",
    "def get_predictions_for_dataframe(\n",
    "    dataframe, model, tokenizer, batch_size=16, device=None,\n",
    "    multi_label=True, threshold=0.5\n",
    "):\n",
    "    \"\"\"\n",
    "    Run inference on dataframe[\"text\"] using model.\n",
    "    \n",
    "    multi_label=True  -> sigmoid + threshold (multi-label classification)\n",
    "    multi_label=False -> softmax + argmax (single-label classification)\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "\n",
    "    dataset = InferenceDataset(dataframe, tokenizer)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            if multi_label:\n",
    "                # multi-label: sigmoid + threshold\n",
    "                probs = torch.sigmoid(logits)\n",
    "                batch_predictions = (probs > threshold).int().cpu().tolist()\n",
    "            else:\n",
    "                # single-label: softmax + argmax\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                batch_predictions = torch.argmax(probs, dim=-1).cpu().tolist()\n",
    "\n",
    "            predictions.extend(batch_predictions)\n",
    "\n",
    "    if multi_label:\n",
    "        # One column per label (0/1)\n",
    "        predictions_df = pd.DataFrame(predictions, columns=LABELS)\n",
    "\n",
    "        # Add human-readable labels\n",
    "        readable_labels = []\n",
    "        for row in predictions_df.values:\n",
    "            active = [LABELS[i] for i, val in enumerate(row) if val == 1]\n",
    "            readable_labels.append(\", \".join(active) if active else \"none\")\n",
    "        predictions_df[\"predicted_labels\"] = readable_labels\n",
    "\n",
    "        result_df = pd.concat([dataframe.reset_index(drop=True), predictions_df], axis=1)\n",
    "    else:\n",
    "        # Single-label: just map index -> label\n",
    "        readable_labels = [LABELS[idx] for idx in predictions]\n",
    "        result_df = dataframe.copy().reset_index(drop=True)\n",
    "        result_df[\"predicted_label\"] = readable_labels\n",
    "\n",
    "    return result_df[\"predicted_labels\"]\n",
    "\n",
    "def engineer_features(df):\n",
    "    df['cleaned_review_text'] = df['review_text'].apply(clean_text)\n",
    "    df['tokenized_review'] = df['cleaned_review_text'].apply(tokenize)\n",
    "    df['review_length'] = df['tokenized_review'].apply(len)\n",
    "    df['all_caps_ratio'] = df['review_text'].apply(all_caps_ratio)\n",
    "    df['sentiment'] = df['cleaned_review_text'].apply(lambda x: sentiment_analyzer(x)[0]['label'])\n",
    "    df['relevancy_score'] = df['review_text'].apply(calculate_relevancy_score)\n",
    "    emotions = get_predictions_for_dataframe(df, model, tokenizer, multi_label=True)\n",
    "    df[\"emotions\"] = emotions\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d7eea2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 1500 to 1549\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   user_name            50 non-null     object \n",
      " 1   review_text          50 non-null     object \n",
      " 2   rating               50 non-null     int64  \n",
      " 3   label                50 non-null     object \n",
      " 4   cleaned_review_text  50 non-null     object \n",
      " 5   tokenized_review     50 non-null     object \n",
      " 6   review_length        50 non-null     int64  \n",
      " 7   all_caps_ratio       50 non-null     float64\n",
      " 8   sentiment            50 non-null     object \n",
      " 9   relevancy_score      50 non-null     int64  \n",
      " 10  emotions             0 non-null      object \n",
      "dtypes: float64(1), int64(3), object(7)\n",
      "memory usage: 4.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_review_text</th>\n",
       "      <th>tokenized_review</th>\n",
       "      <th>review_length</th>\n",
       "      <th>all_caps_ratio</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>relevancy_score</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>Craig H</td>\n",
       "      <td>I’ve had my Sanctuary 2 sauna and red light fo...</td>\n",
       "      <td>5</td>\n",
       "      <td>Valid</td>\n",
       "      <td>ive had my sanctuary  sauna and red light for ...</td>\n",
       "      <td>[ve, sanctuary,  , sauna, red, light, month, l...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>Dr Harold Patino</td>\n",
       "      <td>What can I say! Julie was fantastic and the pr...</td>\n",
       "      <td>5</td>\n",
       "      <td>Valid</td>\n",
       "      <td>what can i say julie was fantastic and the pro...</td>\n",
       "      <td>[julie, fantastic, product,  , sactuary,  , fa...</td>\n",
       "      <td>34</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>Lauren Kilbourne</td>\n",
       "      <td>Thank you so much Julie for your support in pu...</td>\n",
       "      <td>5</td>\n",
       "      <td>Valid</td>\n",
       "      <td>thank you so much julie for your support in pu...</td>\n",
       "      <td>[thank, julie, support, purchasing, clearlight...</td>\n",
       "      <td>56</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>Natural Baby Mama</td>\n",
       "      <td>Julie has been amazing throughout the entire b...</td>\n",
       "      <td>5</td>\n",
       "      <td>Valid</td>\n",
       "      <td>julie has been amazing throughout the entire b...</td>\n",
       "      <td>[julie, amazing, entire, buying, process,  , w...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>Holly McGreevy</td>\n",
       "      <td>Working with Julie was an absolute pleasure! J...</td>\n",
       "      <td>5</td>\n",
       "      <td>Valid</td>\n",
       "      <td>working with julie was an absolute pleasure ju...</td>\n",
       "      <td>[working, julie, absolute, pleasure, julie, ho...</td>\n",
       "      <td>34</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user_name                                        review_text  \\\n",
       "1500            Craig H  I’ve had my Sanctuary 2 sauna and red light fo...   \n",
       "1501   Dr Harold Patino  What can I say! Julie was fantastic and the pr...   \n",
       "1502   Lauren Kilbourne  Thank you so much Julie for your support in pu...   \n",
       "1503  Natural Baby Mama  Julie has been amazing throughout the entire b...   \n",
       "1504     Holly McGreevy  Working with Julie was an absolute pleasure! J...   \n",
       "\n",
       "      rating  label                                cleaned_review_text  \\\n",
       "1500       5  Valid  ive had my sanctuary  sauna and red light for ...   \n",
       "1501       5  Valid  what can i say julie was fantastic and the pro...   \n",
       "1502       5  Valid  thank you so much julie for your support in pu...   \n",
       "1503       5  Valid  julie has been amazing throughout the entire b...   \n",
       "1504       5  Valid  working with julie was an absolute pleasure ju...   \n",
       "\n",
       "                                       tokenized_review  review_length  \\\n",
       "1500  [ve, sanctuary,  , sauna, red, light, month, l...             17   \n",
       "1501  [julie, fantastic, product,  , sactuary,  , fa...             34   \n",
       "1502  [thank, julie, support, purchasing, clearlight...             56   \n",
       "1503  [julie, amazing, entire, buying, process,  , w...             26   \n",
       "1504  [working, julie, absolute, pleasure, julie, ho...             34   \n",
       "\n",
       "      all_caps_ratio sentiment  relevancy_score emotions  \n",
       "1500        0.000000  POSITIVE               55      NaN  \n",
       "1501        0.029851  POSITIVE               72      NaN  \n",
       "1502        0.034188  POSITIVE               97      NaN  \n",
       "1503        0.000000  POSITIVE               65      NaN  \n",
       "1504        0.080645  POSITIVE               69      NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = engineer_features(df2)\n",
    "df2.info()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94401a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"../data/walk_through/walk_through.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
